<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>shign.shign API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>shign.shign</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import argparse

import numpy as np
import scipy.signal

import soundfile as sf
import librosa

from shign.util import ms_to_samples, samples_to_ms, sec_to_frames, frames_to_ms, audio_to_rms_envelope

def get_shift_ms(audio_a, audio_b, sr_a, sr_b, win_length_ms=25., hop_length_ms=10., min_overlap_sec=1., max_shift_sec=30.):
    &#34;&#34;&#34;
    Finds the amount of milliseconds the start of `audio_b` must move to the right in order to align it with `audio_a`.

    Audios are compared by their root-mean-square envelopes. See `shign.util.audio_to_rms_envelope()`.

    The RMS envelope consists of one loudness value for every `hop_length_ms` milliseconds worth of audio.
    The optimal alignment is found by shifting the RMS envelopes and recording the similarity between the envelopes for each amount of shift.
    The amount of shift that maximizes the similarity is the optimial amount of shift.
    A low value for `hop_length_ms` is more precise.
    The measure of similarity is the correlation normalized by the amount of valid (non-padding) entries the correlation is taken over.

    Parameters
    ----------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    sr_a : int
        Samplerate of `audio_a`
    sr_b : int
        Samplerate of `audio_b`
    win_length_ms : float (optional)
        Window length (milliseconds) that&#39;s used to determine the dbfs envelope. If no value is passed, assumes 25 ms.
    hop_length_ms : float
        Hop length (milliseconds) that&#39;s used to determine the dbfs envelope. If no value is passed, assumes 10 ms.
    min_overlap_sec : float
        This function assumes the two audios have at least this amount of overlap (in seconds). If no value is passed, assumes 1 second. Passing a too low value can give inaccurate results.
    max_shift_sec : float
        This function assumes the **center** of `audio_b` does not require more than this amount of shift relative to the **center** of `audio_a`. If the value 0 is passed, all shift candidates are considered.

    Returns
    -------
    shift_ms : float
        The amount of milliseconds the **start** of `audio_b` should move to the right to align the audios
    &#34;&#34;&#34;

    rms_a = audio_to_rms_envelope(audio_a, sr=sr_a, win_length_ms=win_length_ms, hop_length_ms=hop_length_ms)
    rms_b = audio_to_rms_envelope(audio_b, sr=sr_b, win_length_ms=win_length_ms, hop_length_ms=hop_length_ms)

    corr_num   = scipy.signal.correlate(rms_a, rms_b, mode=&#39;full&#39;)
    corr_denom = scipy.signal.correlate(np.ones_like(rms_a), np.ones_like(rms_b), mode=&#39;full&#39;)
    corr       = corr_num / corr_denom
    half_idx   = int(np.round(len(corr) / 2))

    if min_overlap_sec != 0:
        n = sec_to_frames(min_overlap_sec, frame_length_ms=hop_length_ms)
        corr[:n]  = 0
        corr[-n:] = 0

    if max_shift_sec != 0:
        n = sec_to_frames(max_shift_sec, frame_length_ms=hop_length_ms)
        corr[:max(half_idx - n, 0)]         = 0
        corr[min(half_idx + n, len(corr)):] = 0

    shift_idx = np.argmax(corr) - half_idx              # this is the amount of frames the **center** of audio_b should move to the right to match audio_a
    shift_idx = shift_idx + (len(rms_a) - len(rms_b))/2 # this is the amount of frames the **start** of audio_b should move to the right to match audio_a
    shift_ms  = frames_to_ms(shift_idx, frame_length_ms=hop_length_ms)

    return shift_ms

def pad_both(audio_a, audio_b, sr_a, sr_b, shift_ms):
    &#34;&#34;&#34;
    Pads both audios with silence so that they have equal length and are aligned

    Example 1 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4]
    audio_b = [3, 4, 5]
    pad_both(audio_a, audio_b)
    &gt;&gt;&gt; [1, 2, 3, 4, 0]
    &gt;&gt;&gt; [0, 0, 3, 4, 5]
    ```

    Example 2 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4, 5]
    audio_b = [3, 4]
    pad_both(audio_a, audio_b)
    &gt;&gt;&gt; [1, 2, 3, 4, 5]
    &gt;&gt;&gt; [0, 0, 3, 4, 0]
    ```

    Parameters
    ----------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    sr_a : int
        Samplerate of `audio_a`
    sr_b : int
        Samplerate of `audio_b`
    shift_ms : float
        The amount of milliseconds the start of `audio_b` should move to the right to align the audios

    Returns
    -------
    audio_a : np.ndarray
        Array of waveform values that may have leading or trailing silence
    audio_b : np.ndarray
        Array of waveform values that may have leading or trailing silence
    &#34;&#34;&#34;

    # The amount of ms the start of audio_b should shift to the right
    shift_start_ms   = shift_ms
    shift_start_a_ms = -min(0, shift_start_ms)
    shift_start_b_ms = max(0, shift_start_ms)

    shift_start_a_samples = ms_to_samples(shift_start_a_ms, sr=sr_a)
    shift_start_b_samples = ms_to_samples(shift_start_b_ms, sr=sr_b)

    audio_a = np.concatenate([np.zeros(shift_start_a_samples), audio_a], axis=0)
    audio_b = np.concatenate([np.zeros(shift_start_b_samples), audio_b], axis=0)

    # The amount of ms the end of audio_b should move to the right
    shift_end_ms   = samples_to_ms(len(audio_a), sr=sr_a) - samples_to_ms(len(audio_b), sr=sr_b)
    shift_end_a_ms = -min(0, shift_end_ms)
    shift_end_b_ms = max(0, shift_end_ms)

    shift_end_a_samples = ms_to_samples(shift_end_a_ms, sr=sr_a)
    shift_end_b_samples = ms_to_samples(shift_end_b_ms, sr=sr_b)

    audio_a = np.concatenate([audio_a, np.zeros(shift_end_a_samples)], axis=0)
    audio_b = np.concatenate([audio_b, np.zeros(shift_end_b_samples)], axis=0)

    return audio_a, audio_b

def crop_both(audio_a, audio_b, sr_a, sr_b, shift_ms):
    &#34;&#34;&#34;
    Crops both audios with silence so that they have equal length and are aligned

    Example 1 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4]
    audio_b = [3, 4, 5]
    crop_both(audio_a, audio_b)
    &gt;&gt;&gt; [3, 4]
    &gt;&gt;&gt; [3, 4]
    ```

    Example 2 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4, 5]
    audio_b = [3, 4]
    crop_both(audio_a, audio_b)
    &gt;&gt;&gt; [3, 4]
    &gt;&gt;&gt; [3, 4]
    ```

    Parameters
    ----------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    sr_a : int
        Samplerate of `audio_a`
    sr_b : int
        Samplerate of `audio_b`
    shift_ms : float
        The amount of milliseconds the start of `audio_b` should move to the right to align the audios

    Returns
    -------
    audio_a : np.ndarray
        Array of waveform values that may have shorter length than the input
    audio_b : np.ndarray
        Array of waveform values that may have shorter length than the input
    &#34;&#34;&#34;

    # The amount of ms the start of audio_b should shift to the right
    shift_start_ms   = shift_ms
    shift_start_a_ms = -min(0, shift_start_ms)
    shift_start_b_ms = max(0, shift_start_ms)

    shift_start_a_samples = ms_to_samples(shift_start_a_ms, sr=sr_a)
    shift_start_b_samples = ms_to_samples(shift_start_b_ms, sr=sr_b)

    audio_a = audio_a[shift_start_a_samples:]
    audio_b = audio_b[shift_start_b_samples:]

    # The amount of ms the end of audio_b should move to the right
    shift_end_ms   = samples_to_ms(len(audio_a), sr=sr_a) - samples_to_ms(len(audio_b), sr=sr_b)
    shift_end_a_ms = -min(0, shift_end_ms)
    shift_end_b_ms = max(0, shift_end_ms)

    shift_end_a_samples = ms_to_samples(shift_end_a_ms, sr=sr_a)
    shift_end_b_samples = ms_to_samples(shift_end_b_ms, sr=sr_b)

    audio_a = audio_a[:-shift_end_a_samples]
    audio_b = audio_b[:-shift_end_b_samples]

    return audio_a, audio_b

def pad_and_crop_one_to_match_other(audio_a, audio_b, sr_a, sr_b, shift_ms):
    &#34;&#34;&#34;
    Applies padding and cropping to one audio file so that its start and end match the start and end of the leading audio

    This function only manipulates `audio_a` and does not manipulate `audio_b`

    Example 1 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4]
    audio_b = [3, 4, 5]
    pad_and_crop_one_to_match_other(audio_a, audio_b)
    &gt;&gt;&gt; [3, 4, 0]
    &gt;&gt;&gt; [3, 4, 5]
    ```

    Example 2 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4, 5]
    audio_b = [3, 4]
    pad_and_crop_one_to_match_other(audio_a, audio_b)
    &gt;&gt;&gt; [3, 4]
    &gt;&gt;&gt; [3, 4]
    ```

    Parameters
    ----------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    sr_a : int
        Samplerate of `audio_a`
    sr_b : int
        Samplerate of `audio_b`
    shift_ms : float
        The amount of milliseconds the start of `audio_b` should move to the right to align the audios

    Returns
    -------
    audio_a : np.ndarray
        Array of waveform values equal to `audio_a` at input
    audio_b : np.ndarray
        Array of waveform values that may have longer or shorter length than the input and may have leading or trailing silence
    &#34;&#34;&#34;

    # The amount of ms the start of audio_b should shift to the right
    shift_start_ms      = shift_ms
    shift_start_samples = ms_to_samples(shift_start_ms, sr=sr_b)

    if shift_start_samples &lt; 0:
        audio_b = audio_b[shift_start_samples:]
    else:
        audio_b = np.concatenate([np.zeros(shift_start_samples), audio_b], axis=0)

    # The amount of ms the end of audio_b should move to the right
    shift_end_ms      = samples_to_ms(len(audio_a), sr=sr_a) - samples_to_ms(len(audio_b), sr=sr_b)
    shift_end_samples = ms_to_samples(shift_end_ms, sr=sr_b)

    if shift_end_samples &lt; 0:
        audio_b = audio_b[:-shift_end_samples]
    else:
        audio_b = np.concatenate([audio_b, np.zeros(shift_end_samples)], axis=0)

    return audio_a, audio_b

def shift_align(audio_a, audio_b, sr_a=None, sr_b=None, align_how=&#34;pad_both&#34;, min_overlap_sec=1., max_shift_sec=30.):
    &#34;&#34;&#34;
    Shifts two audios to align them in time.
    The audios must be recordings of the same audio event.

    The amount of shift required to align the audios is found by comparing the root-mean-square envelopes of the audios. See `get_shift_ms()`

    The way audios will be shifted to match each other depends on the parameter `align_how`:

    - `&#34;pad_both&#34;`: both audios will be padded with the necessary amount of silence on the leading and trailing ends. This way no audio will get lost, but aligned audio files may contain a lot of silence.
    - `&#34;crop_both&#34;`: both audios will have their leading and trailing ends cropped to the necessary amount. This only keeps the audio of the event both audios have a recording of. Audio at the tails gets lost.
    - `&#34;pad_and_crop_one_to_match_other&#34;`: only `audio_b` will be modified, either cropped or padded, in order to match `audio_a`. `audio_a` will remain unmodified.

    Parameters
    ----------
    audio_a : np.ndarray or string
        If the input is an array, it will be interpreted as an audio that needs to be aligned to `audio_b`.
        If the input is a string, it will be interpreted as the path to the audio that needs to be loaded.
    audio_b : np.ndarray or string
        If the input is an array, it will be interpreted as an audio that needs to be aligned to `audio_a`.
        If the input is a string, it will be interpreted as the path to the audio that needs to be loaded.
    sr_a : int
        Samplerate of `audio_a`
        If `audio_a` is a string, the audio in that path will be forcibly resampled to `sr_a`. If `sr_a` is `None`, the native samplerate will be used.
    sr_b : int
        Samplerate of `audio_b`
        If `audio_b` is a string, the audio in that path will be forcibly resampled to `sr_b`. If `sr_b` is `None`, the native samplerate will be used.
    align_how : string
        How the audios will be aligned to each other.

    Returns
    -------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    &#34;&#34;&#34;

    if isinstance(audio_a, str):
        audio_a, sr_a = librosa.load(audio_a, sr=sr_a)
    if isinstance(audio_b, str):
        audio_b, sr_b = librosa.load(audio_b, sr=sr_b)

    assert sr_a is not None, &#34;please submit a path to an audio file or an audio array with explicit samplerate&#34;
    assert sr_b is not None, &#34;please submit a path to an audio file or an audio array with explicit samplerate&#34;

    shift_ms = get_shift_ms(audio_a, audio_b, sr_a, sr_b, min_overlap_sec=min_overlap_sec, max_shift_sec=max_shift_sec)

    if   align_how == &#34;pad_both&#34;:
        audio_a, audio_b = pad_both(audio_a, audio_b, sr_a, sr_b, shift_ms)
    elif align_how == &#34;crop_both&#34;:
        audio_a, audio_b = crop_both(audio_a, audio_b, sr_a, sr_b, shift_ms)
    elif align_how == &#34;pad_and_crop_one_to_match_other&#34;:
        audio_a, audio_b = pad_and_crop_one_to_match_other(audio_a, audio_b, sr_a, sr_b, shift_ms)
    else:
        raise Exception(f&#34;Unknown value for align_how {align_how}&#34;)

    return audio_a, audio_b

if __name__ == &#34;__main__&#34;:
    parser = argparse.ArgumentParser()

    parser.add_argument(&#34;-i&#34;, type=str, nargs=2)
    parser.add_argument(&#34;-o&#34;, type=str, nargs=2)
    parser.add_argument(&#34;--align_how&#34;, type=str, default=&#34;pad_both&#34;)
    parser.add_argument(&#34;--min_overlap_sec&#34;, type=float, default=1.)
    parser.add_argument(&#34;--max_shift_sec&#34;, type=float, default=30.)

    args = parser.parse_args()

    audio_a, audio_b = shift_align(args[&#34;i&#34;][0], args[&#34;i&#34;][1], align_how=args[&#34;align_how&#34;], min_overlap_sec=args[&#34;min_overlap_sec&#34;], max_shift_sec=args[&#34;max_shift_sec&#34;])

    sf.write(data=audio_a, file=args[&#34;o&#34;][0], rate=sf.info(args[&#34;i&#34;][0]).samplerate)
    sf.write(data=audio_b, file=args[&#34;o&#34;][1], rate=sf.info(args[&#34;i&#34;][1]).samplerate)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="shign.shign.crop_both"><code class="name flex">
<span>def <span class="ident">crop_both</span></span>(<span>audio_a, audio_b, sr_a, sr_b, shift_ms)</span>
</code></dt>
<dd>
<div class="desc"><p>Crops both audios with silence so that they have equal length and are aligned</p>
<p>Example 1 (psuedocode):</p>
<pre><code>audio_a = [1, 2, 3, 4]
audio_b = [3, 4, 5]
crop_both(audio_a, audio_b)
&gt;&gt;&gt; [3, 4]
&gt;&gt;&gt; [3, 4]
</code></pre>
<p>Example 2 (psuedocode):</p>
<pre><code>audio_a = [1, 2, 3, 4, 5]
audio_b = [3, 4]
crop_both(audio_a, audio_b)
&gt;&gt;&gt; [3, 4]
&gt;&gt;&gt; [3, 4]
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>audio_a</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
<dt><strong><code>audio_b</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
<dt><strong><code>sr_a</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_a</code></dd>
<dt><strong><code>sr_b</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_b</code></dd>
<dt><strong><code>shift_ms</code></strong> :&ensp;<code>float</code></dt>
<dd>The amount of milliseconds the start of <code>audio_b</code> should move to the right to align the audios</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>audio_a</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values that may have shorter length than the input</dd>
<dt><strong><code>audio_b</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values that may have shorter length than the input</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop_both(audio_a, audio_b, sr_a, sr_b, shift_ms):
    &#34;&#34;&#34;
    Crops both audios with silence so that they have equal length and are aligned

    Example 1 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4]
    audio_b = [3, 4, 5]
    crop_both(audio_a, audio_b)
    &gt;&gt;&gt; [3, 4]
    &gt;&gt;&gt; [3, 4]
    ```

    Example 2 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4, 5]
    audio_b = [3, 4]
    crop_both(audio_a, audio_b)
    &gt;&gt;&gt; [3, 4]
    &gt;&gt;&gt; [3, 4]
    ```

    Parameters
    ----------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    sr_a : int
        Samplerate of `audio_a`
    sr_b : int
        Samplerate of `audio_b`
    shift_ms : float
        The amount of milliseconds the start of `audio_b` should move to the right to align the audios

    Returns
    -------
    audio_a : np.ndarray
        Array of waveform values that may have shorter length than the input
    audio_b : np.ndarray
        Array of waveform values that may have shorter length than the input
    &#34;&#34;&#34;

    # The amount of ms the start of audio_b should shift to the right
    shift_start_ms   = shift_ms
    shift_start_a_ms = -min(0, shift_start_ms)
    shift_start_b_ms = max(0, shift_start_ms)

    shift_start_a_samples = ms_to_samples(shift_start_a_ms, sr=sr_a)
    shift_start_b_samples = ms_to_samples(shift_start_b_ms, sr=sr_b)

    audio_a = audio_a[shift_start_a_samples:]
    audio_b = audio_b[shift_start_b_samples:]

    # The amount of ms the end of audio_b should move to the right
    shift_end_ms   = samples_to_ms(len(audio_a), sr=sr_a) - samples_to_ms(len(audio_b), sr=sr_b)
    shift_end_a_ms = -min(0, shift_end_ms)
    shift_end_b_ms = max(0, shift_end_ms)

    shift_end_a_samples = ms_to_samples(shift_end_a_ms, sr=sr_a)
    shift_end_b_samples = ms_to_samples(shift_end_b_ms, sr=sr_b)

    audio_a = audio_a[:-shift_end_a_samples]
    audio_b = audio_b[:-shift_end_b_samples]

    return audio_a, audio_b</code></pre>
</details>
</dd>
<dt id="shign.shign.get_shift_ms"><code class="name flex">
<span>def <span class="ident">get_shift_ms</span></span>(<span>audio_a, audio_b, sr_a, sr_b, win_length_ms=25.0, hop_length_ms=10.0, min_overlap_sec=1.0, max_shift_sec=30.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the amount of milliseconds the start of <code>audio_b</code> must move to the right in order to align it with <code>audio_a</code>.</p>
<p>Audios are compared by their root-mean-square envelopes. See <code><a title="shign.util.audio_to_rms_envelope" href="util.html#shign.util.audio_to_rms_envelope">audio_to_rms_envelope()</a></code>.</p>
<p>The RMS envelope consists of one loudness value for every <code>hop_length_ms</code> milliseconds worth of audio.
The optimal alignment is found by shifting the RMS envelopes and recording the similarity between the envelopes for each amount of shift.
The amount of shift that maximizes the similarity is the optimial amount of shift.
A low value for <code>hop_length_ms</code> is more precise.
The measure of similarity is the correlation normalized by the amount of valid (non-padding) entries the correlation is taken over.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>audio_a</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
<dt><strong><code>audio_b</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
<dt><strong><code>sr_a</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_a</code></dd>
<dt><strong><code>sr_b</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_b</code></dd>
<dt><strong><code>win_length_ms</code></strong> :&ensp;<code>float (optional)</code></dt>
<dd>Window length (milliseconds) that's used to determine the dbfs envelope. If no value is passed, assumes 25 ms.</dd>
<dt><strong><code>hop_length_ms</code></strong> :&ensp;<code>float</code></dt>
<dd>Hop length (milliseconds) that's used to determine the dbfs envelope. If no value is passed, assumes 10 ms.</dd>
<dt><strong><code>min_overlap_sec</code></strong> :&ensp;<code>float</code></dt>
<dd>This function assumes the two audios have at least this amount of overlap (in seconds). If no value is passed, assumes 1 second. Passing a too low value can give inaccurate results.</dd>
<dt><strong><code>max_shift_sec</code></strong> :&ensp;<code>float</code></dt>
<dd>This function assumes the <strong>center</strong> of <code>audio_b</code> does not require more than this amount of shift relative to the <strong>center</strong> of <code>audio_a</code>. If the value 0 is passed, all shift candidates are considered.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>shift_ms</code></strong> :&ensp;<code>float</code></dt>
<dd>The amount of milliseconds the <strong>start</strong> of <code>audio_b</code> should move to the right to align the audios</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_shift_ms(audio_a, audio_b, sr_a, sr_b, win_length_ms=25., hop_length_ms=10., min_overlap_sec=1., max_shift_sec=30.):
    &#34;&#34;&#34;
    Finds the amount of milliseconds the start of `audio_b` must move to the right in order to align it with `audio_a`.

    Audios are compared by their root-mean-square envelopes. See `shign.util.audio_to_rms_envelope()`.

    The RMS envelope consists of one loudness value for every `hop_length_ms` milliseconds worth of audio.
    The optimal alignment is found by shifting the RMS envelopes and recording the similarity between the envelopes for each amount of shift.
    The amount of shift that maximizes the similarity is the optimial amount of shift.
    A low value for `hop_length_ms` is more precise.
    The measure of similarity is the correlation normalized by the amount of valid (non-padding) entries the correlation is taken over.

    Parameters
    ----------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    sr_a : int
        Samplerate of `audio_a`
    sr_b : int
        Samplerate of `audio_b`
    win_length_ms : float (optional)
        Window length (milliseconds) that&#39;s used to determine the dbfs envelope. If no value is passed, assumes 25 ms.
    hop_length_ms : float
        Hop length (milliseconds) that&#39;s used to determine the dbfs envelope. If no value is passed, assumes 10 ms.
    min_overlap_sec : float
        This function assumes the two audios have at least this amount of overlap (in seconds). If no value is passed, assumes 1 second. Passing a too low value can give inaccurate results.
    max_shift_sec : float
        This function assumes the **center** of `audio_b` does not require more than this amount of shift relative to the **center** of `audio_a`. If the value 0 is passed, all shift candidates are considered.

    Returns
    -------
    shift_ms : float
        The amount of milliseconds the **start** of `audio_b` should move to the right to align the audios
    &#34;&#34;&#34;

    rms_a = audio_to_rms_envelope(audio_a, sr=sr_a, win_length_ms=win_length_ms, hop_length_ms=hop_length_ms)
    rms_b = audio_to_rms_envelope(audio_b, sr=sr_b, win_length_ms=win_length_ms, hop_length_ms=hop_length_ms)

    corr_num   = scipy.signal.correlate(rms_a, rms_b, mode=&#39;full&#39;)
    corr_denom = scipy.signal.correlate(np.ones_like(rms_a), np.ones_like(rms_b), mode=&#39;full&#39;)
    corr       = corr_num / corr_denom
    half_idx   = int(np.round(len(corr) / 2))

    if min_overlap_sec != 0:
        n = sec_to_frames(min_overlap_sec, frame_length_ms=hop_length_ms)
        corr[:n]  = 0
        corr[-n:] = 0

    if max_shift_sec != 0:
        n = sec_to_frames(max_shift_sec, frame_length_ms=hop_length_ms)
        corr[:max(half_idx - n, 0)]         = 0
        corr[min(half_idx + n, len(corr)):] = 0

    shift_idx = np.argmax(corr) - half_idx              # this is the amount of frames the **center** of audio_b should move to the right to match audio_a
    shift_idx = shift_idx + (len(rms_a) - len(rms_b))/2 # this is the amount of frames the **start** of audio_b should move to the right to match audio_a
    shift_ms  = frames_to_ms(shift_idx, frame_length_ms=hop_length_ms)

    return shift_ms</code></pre>
</details>
</dd>
<dt id="shign.shign.pad_and_crop_one_to_match_other"><code class="name flex">
<span>def <span class="ident">pad_and_crop_one_to_match_other</span></span>(<span>audio_a, audio_b, sr_a, sr_b, shift_ms)</span>
</code></dt>
<dd>
<div class="desc"><p>Applies padding and cropping to one audio file so that its start and end match the start and end of the leading audio</p>
<p>This function only manipulates <code>audio_a</code> and does not manipulate <code>audio_b</code></p>
<p>Example 1 (psuedocode):</p>
<pre><code>audio_a = [1, 2, 3, 4]
audio_b = [3, 4, 5]
pad_and_crop_one_to_match_other(audio_a, audio_b)
&gt;&gt;&gt; [3, 4, 0]
&gt;&gt;&gt; [3, 4, 5]
</code></pre>
<p>Example 2 (psuedocode):</p>
<pre><code>audio_a = [1, 2, 3, 4, 5]
audio_b = [3, 4]
pad_and_crop_one_to_match_other(audio_a, audio_b)
&gt;&gt;&gt; [3, 4]
&gt;&gt;&gt; [3, 4]
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>audio_a</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
<dt><strong><code>audio_b</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
<dt><strong><code>sr_a</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_a</code></dd>
<dt><strong><code>sr_b</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_b</code></dd>
<dt><strong><code>shift_ms</code></strong> :&ensp;<code>float</code></dt>
<dd>The amount of milliseconds the start of <code>audio_b</code> should move to the right to align the audios</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>audio_a</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values equal to <code>audio_a</code> at input</dd>
<dt><strong><code>audio_b</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values that may have longer or shorter length than the input and may have leading or trailing silence</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pad_and_crop_one_to_match_other(audio_a, audio_b, sr_a, sr_b, shift_ms):
    &#34;&#34;&#34;
    Applies padding and cropping to one audio file so that its start and end match the start and end of the leading audio

    This function only manipulates `audio_a` and does not manipulate `audio_b`

    Example 1 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4]
    audio_b = [3, 4, 5]
    pad_and_crop_one_to_match_other(audio_a, audio_b)
    &gt;&gt;&gt; [3, 4, 0]
    &gt;&gt;&gt; [3, 4, 5]
    ```

    Example 2 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4, 5]
    audio_b = [3, 4]
    pad_and_crop_one_to_match_other(audio_a, audio_b)
    &gt;&gt;&gt; [3, 4]
    &gt;&gt;&gt; [3, 4]
    ```

    Parameters
    ----------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    sr_a : int
        Samplerate of `audio_a`
    sr_b : int
        Samplerate of `audio_b`
    shift_ms : float
        The amount of milliseconds the start of `audio_b` should move to the right to align the audios

    Returns
    -------
    audio_a : np.ndarray
        Array of waveform values equal to `audio_a` at input
    audio_b : np.ndarray
        Array of waveform values that may have longer or shorter length than the input and may have leading or trailing silence
    &#34;&#34;&#34;

    # The amount of ms the start of audio_b should shift to the right
    shift_start_ms      = shift_ms
    shift_start_samples = ms_to_samples(shift_start_ms, sr=sr_b)

    if shift_start_samples &lt; 0:
        audio_b = audio_b[shift_start_samples:]
    else:
        audio_b = np.concatenate([np.zeros(shift_start_samples), audio_b], axis=0)

    # The amount of ms the end of audio_b should move to the right
    shift_end_ms      = samples_to_ms(len(audio_a), sr=sr_a) - samples_to_ms(len(audio_b), sr=sr_b)
    shift_end_samples = ms_to_samples(shift_end_ms, sr=sr_b)

    if shift_end_samples &lt; 0:
        audio_b = audio_b[:-shift_end_samples]
    else:
        audio_b = np.concatenate([audio_b, np.zeros(shift_end_samples)], axis=0)

    return audio_a, audio_b</code></pre>
</details>
</dd>
<dt id="shign.shign.pad_both"><code class="name flex">
<span>def <span class="ident">pad_both</span></span>(<span>audio_a, audio_b, sr_a, sr_b, shift_ms)</span>
</code></dt>
<dd>
<div class="desc"><p>Pads both audios with silence so that they have equal length and are aligned</p>
<p>Example 1 (psuedocode):</p>
<pre><code>audio_a = [1, 2, 3, 4]
audio_b = [3, 4, 5]
pad_both(audio_a, audio_b)
&gt;&gt;&gt; [1, 2, 3, 4, 0]
&gt;&gt;&gt; [0, 0, 3, 4, 5]
</code></pre>
<p>Example 2 (psuedocode):</p>
<pre><code>audio_a = [1, 2, 3, 4, 5]
audio_b = [3, 4]
pad_both(audio_a, audio_b)
&gt;&gt;&gt; [1, 2, 3, 4, 5]
&gt;&gt;&gt; [0, 0, 3, 4, 0]
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>audio_a</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
<dt><strong><code>audio_b</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
<dt><strong><code>sr_a</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_a</code></dd>
<dt><strong><code>sr_b</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_b</code></dd>
<dt><strong><code>shift_ms</code></strong> :&ensp;<code>float</code></dt>
<dd>The amount of milliseconds the start of <code>audio_b</code> should move to the right to align the audios</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>audio_a</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values that may have leading or trailing silence</dd>
<dt><strong><code>audio_b</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values that may have leading or trailing silence</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pad_both(audio_a, audio_b, sr_a, sr_b, shift_ms):
    &#34;&#34;&#34;
    Pads both audios with silence so that they have equal length and are aligned

    Example 1 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4]
    audio_b = [3, 4, 5]
    pad_both(audio_a, audio_b)
    &gt;&gt;&gt; [1, 2, 3, 4, 0]
    &gt;&gt;&gt; [0, 0, 3, 4, 5]
    ```

    Example 2 (psuedocode):
    ```
    audio_a = [1, 2, 3, 4, 5]
    audio_b = [3, 4]
    pad_both(audio_a, audio_b)
    &gt;&gt;&gt; [1, 2, 3, 4, 5]
    &gt;&gt;&gt; [0, 0, 3, 4, 0]
    ```

    Parameters
    ----------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    sr_a : int
        Samplerate of `audio_a`
    sr_b : int
        Samplerate of `audio_b`
    shift_ms : float
        The amount of milliseconds the start of `audio_b` should move to the right to align the audios

    Returns
    -------
    audio_a : np.ndarray
        Array of waveform values that may have leading or trailing silence
    audio_b : np.ndarray
        Array of waveform values that may have leading or trailing silence
    &#34;&#34;&#34;

    # The amount of ms the start of audio_b should shift to the right
    shift_start_ms   = shift_ms
    shift_start_a_ms = -min(0, shift_start_ms)
    shift_start_b_ms = max(0, shift_start_ms)

    shift_start_a_samples = ms_to_samples(shift_start_a_ms, sr=sr_a)
    shift_start_b_samples = ms_to_samples(shift_start_b_ms, sr=sr_b)

    audio_a = np.concatenate([np.zeros(shift_start_a_samples), audio_a], axis=0)
    audio_b = np.concatenate([np.zeros(shift_start_b_samples), audio_b], axis=0)

    # The amount of ms the end of audio_b should move to the right
    shift_end_ms   = samples_to_ms(len(audio_a), sr=sr_a) - samples_to_ms(len(audio_b), sr=sr_b)
    shift_end_a_ms = -min(0, shift_end_ms)
    shift_end_b_ms = max(0, shift_end_ms)

    shift_end_a_samples = ms_to_samples(shift_end_a_ms, sr=sr_a)
    shift_end_b_samples = ms_to_samples(shift_end_b_ms, sr=sr_b)

    audio_a = np.concatenate([audio_a, np.zeros(shift_end_a_samples)], axis=0)
    audio_b = np.concatenate([audio_b, np.zeros(shift_end_b_samples)], axis=0)

    return audio_a, audio_b</code></pre>
</details>
</dd>
<dt id="shign.shign.shift_align"><code class="name flex">
<span>def <span class="ident">shift_align</span></span>(<span>audio_a, audio_b, sr_a=None, sr_b=None, align_how='pad_both', min_overlap_sec=1.0, max_shift_sec=30.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Shifts two audios to align them in time.
The audios must be recordings of the same audio event.</p>
<p>The amount of shift required to align the audios is found by comparing the root-mean-square envelopes of the audios. See <code><a title="shign.shign.get_shift_ms" href="#shign.shign.get_shift_ms">get_shift_ms()</a></code></p>
<p>The way audios will be shifted to match each other depends on the parameter <code>align_how</code>:</p>
<ul>
<li><code>"pad_both"</code>: both audios will be padded with the necessary amount of silence on the leading and trailing ends. This way no audio will get lost, but aligned audio files may contain a lot of silence.</li>
<li><code>"crop_both"</code>: both audios will have their leading and trailing ends cropped to the necessary amount. This only keeps the audio of the event both audios have a recording of. Audio at the tails gets lost.</li>
<li><code>"pad_and_crop_one_to_match_other"</code>: only <code>audio_b</code> will be modified, either cropped or padded, in order to match <code>audio_a</code>. <code>audio_a</code> will remain unmodified.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>audio_a</code></strong> :&ensp;<code>np.ndarray</code> or <code>string</code></dt>
<dd>If the input is an array, it will be interpreted as an audio that needs to be aligned to <code>audio_b</code>.
If the input is a string, it will be interpreted as the path to the audio that needs to be loaded.</dd>
<dt><strong><code>audio_b</code></strong> :&ensp;<code>np.ndarray</code> or <code>string</code></dt>
<dd>If the input is an array, it will be interpreted as an audio that needs to be aligned to <code>audio_a</code>.
If the input is a string, it will be interpreted as the path to the audio that needs to be loaded.</dd>
<dt><strong><code>sr_a</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_a</code>
If <code>audio_a</code> is a string, the audio in that path will be forcibly resampled to <code>sr_a</code>. If <code>sr_a</code> is <code>None</code>, the native samplerate will be used.</dd>
<dt><strong><code>sr_b</code></strong> :&ensp;<code>int</code></dt>
<dd>Samplerate of <code>audio_b</code>
If <code>audio_b</code> is a string, the audio in that path will be forcibly resampled to <code>sr_b</code>. If <code>sr_b</code> is <code>None</code>, the native samplerate will be used.</dd>
<dt><strong><code>align_how</code></strong> :&ensp;<code>string</code></dt>
<dd>How the audios will be aligned to each other.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>audio_a</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
<dt><strong><code>audio_b</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Array of waveform values</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shift_align(audio_a, audio_b, sr_a=None, sr_b=None, align_how=&#34;pad_both&#34;, min_overlap_sec=1., max_shift_sec=30.):
    &#34;&#34;&#34;
    Shifts two audios to align them in time.
    The audios must be recordings of the same audio event.

    The amount of shift required to align the audios is found by comparing the root-mean-square envelopes of the audios. See `get_shift_ms()`

    The way audios will be shifted to match each other depends on the parameter `align_how`:

    - `&#34;pad_both&#34;`: both audios will be padded with the necessary amount of silence on the leading and trailing ends. This way no audio will get lost, but aligned audio files may contain a lot of silence.
    - `&#34;crop_both&#34;`: both audios will have their leading and trailing ends cropped to the necessary amount. This only keeps the audio of the event both audios have a recording of. Audio at the tails gets lost.
    - `&#34;pad_and_crop_one_to_match_other&#34;`: only `audio_b` will be modified, either cropped or padded, in order to match `audio_a`. `audio_a` will remain unmodified.

    Parameters
    ----------
    audio_a : np.ndarray or string
        If the input is an array, it will be interpreted as an audio that needs to be aligned to `audio_b`.
        If the input is a string, it will be interpreted as the path to the audio that needs to be loaded.
    audio_b : np.ndarray or string
        If the input is an array, it will be interpreted as an audio that needs to be aligned to `audio_a`.
        If the input is a string, it will be interpreted as the path to the audio that needs to be loaded.
    sr_a : int
        Samplerate of `audio_a`
        If `audio_a` is a string, the audio in that path will be forcibly resampled to `sr_a`. If `sr_a` is `None`, the native samplerate will be used.
    sr_b : int
        Samplerate of `audio_b`
        If `audio_b` is a string, the audio in that path will be forcibly resampled to `sr_b`. If `sr_b` is `None`, the native samplerate will be used.
    align_how : string
        How the audios will be aligned to each other.

    Returns
    -------
    audio_a : np.ndarray
        Array of waveform values
    audio_b : np.ndarray
        Array of waveform values
    &#34;&#34;&#34;

    if isinstance(audio_a, str):
        audio_a, sr_a = librosa.load(audio_a, sr=sr_a)
    if isinstance(audio_b, str):
        audio_b, sr_b = librosa.load(audio_b, sr=sr_b)

    assert sr_a is not None, &#34;please submit a path to an audio file or an audio array with explicit samplerate&#34;
    assert sr_b is not None, &#34;please submit a path to an audio file or an audio array with explicit samplerate&#34;

    shift_ms = get_shift_ms(audio_a, audio_b, sr_a, sr_b, min_overlap_sec=min_overlap_sec, max_shift_sec=max_shift_sec)

    if   align_how == &#34;pad_both&#34;:
        audio_a, audio_b = pad_both(audio_a, audio_b, sr_a, sr_b, shift_ms)
    elif align_how == &#34;crop_both&#34;:
        audio_a, audio_b = crop_both(audio_a, audio_b, sr_a, sr_b, shift_ms)
    elif align_how == &#34;pad_and_crop_one_to_match_other&#34;:
        audio_a, audio_b = pad_and_crop_one_to_match_other(audio_a, audio_b, sr_a, sr_b, shift_ms)
    else:
        raise Exception(f&#34;Unknown value for align_how {align_how}&#34;)

    return audio_a, audio_b</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="shign" href="index.html">shign</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="shign.shign.crop_both" href="#shign.shign.crop_both">crop_both</a></code></li>
<li><code><a title="shign.shign.get_shift_ms" href="#shign.shign.get_shift_ms">get_shift_ms</a></code></li>
<li><code><a title="shign.shign.pad_and_crop_one_to_match_other" href="#shign.shign.pad_and_crop_one_to_match_other">pad_and_crop_one_to_match_other</a></code></li>
<li><code><a title="shign.shign.pad_both" href="#shign.shign.pad_both">pad_both</a></code></li>
<li><code><a title="shign.shign.shift_align" href="#shign.shign.shift_align">shift_align</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>